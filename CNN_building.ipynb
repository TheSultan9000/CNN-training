{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting the GPU memory consumption growth (to avoid out of memory errors)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information about the directory so that the images can be read\n",
    "data_dir = \"CNN Images\"\n",
    "os.remove(os.path.join(data_dir, '.DS_Store'))\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each image in each directory and check to see if they can be opened and if they match the accepted fire extnesions (image_exts)\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                os.remove(image_path)\n",
    "        except:\n",
    "            os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data using keras- the defult size will be 256x256 with 32 images within each batch\n",
    "# Keras will also autoshuffle the dataset\n",
    "data = tf.keras.utils.image_dataset_from_directory('Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data iterator so that we can move through the batches created by keras\n",
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through the batchs\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch information\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the first 4 images of the batch showing the class numebr\n",
    "fig, ax = plt.subplots(ncols= 4, figsize= (20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data so that the intensity values (0-225) are scaled between 0 and 1\n",
    "data_scaled = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data iterator so that we can move through the batches created by keras\n",
    "data_iterator_scaled = data_scaled.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through the batchs\n",
    "batch_scaled = data_iterator_scaled.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_scaled[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the first 4 images of the batch showing the class numebr\n",
    "fig, ax = plt.subplots(ncols= 4, figsize= (20,20))\n",
    "for idx, img in enumerate(batch_scaled[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch_scaled[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation and test datasets\n",
    "train_size = int(len(data_scaled)*0.7)\n",
    "val_size = int(len(data_scaled)*0.2)\n",
    "test_size = int(len(data_scaled)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the sizes- the split may need to be adjusted if len(data_scaled) != train_size+val_size+test_size\n",
    "print(len(data_scaled))\n",
    "print(train_size+val_size+test_size)\n",
    "print(train_size)\n",
    "print(val_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating datasets\n",
    "training_dataset = data_scaled.take(train_size)\n",
    "val_dataset = data_scaled.skip(train_size).take(val_size)\n",
    "test_dataset = data_scaled.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model container\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN\n",
    "model.add(Conv2D(16,3,1,activation='relu',input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,3,1,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16,3,1,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3,activation='softmax')) #3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile('adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key metrics are logged within the log directory\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(training_dataset, epochs=20, validation_data=val_dataset, callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loss\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'],color='teal',label='loss')\n",
    "plt.plot(history.history['val_loss'],color='orange',label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'],color='teal',label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'],color='orange',label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the precision, recall and accuracy of the model\n",
    "precision_metric = Precision()\n",
    "recall_metric = Recall()\n",
    "accuracy_metric = BinaryAccuracy()\n",
    "\n",
    "for batch in test_dataset.as_numpy_iterator():\n",
    "    x,y = batch\n",
    "    yhat = model.predict(x)\n",
    "    yhat= yhat.argmax(axis=1)\n",
    "    precision_metric.update_state(y, yhat)\n",
    "    recall_metric.update_state(y, yhat)\n",
    "    accuracy_metric.update_state(y, yhat)\n",
    "\n",
    "print(f\"Precision: {precision_metric.result().numpy()}, Recall: {recall_metric.result().numpy()}, Accuracy: {accuracy_metric.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the model\n",
    "def test_image_cnn(img_dir):\n",
    "    '''Test the CNN\n",
    "    Expects: String: Image directory\n",
    "    Modifies: Resizes image to 256x256 and scales pixel vales between 0 and 1\n",
    "    Returns: String: Animal, Building, or Nature based on probabilities\n",
    "    '''\n",
    "    test_image = cv2.cvtColor(cv2.imread(img_dir), cv2.COLOR_BGR2RGB)\n",
    "    test_image_resize = tf.image.resize(test_image, (256,256))\n",
    "    plt.imshow(test_image_resize.numpy().astype(int))\n",
    "    plt.show()\n",
    "\n",
    "    result = model.predict(np.expand_dims(test_image_resize/255,0))\n",
    "    indices = np.argsort(result[0])[-3:]\n",
    "\n",
    "    for i in indices:\n",
    "        if result[0][i] >= 0.1:\n",
    "            if i == 0:\n",
    "                print(f\"Animal: {result[0][i]}\")\n",
    "            if i == 1:\n",
    "                print(f\"Building: {result[0][i]}\")\n",
    "            if i == 2:\n",
    "                print(f\"Nature {result[0][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('CNN.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
